"""
LLM Knowledge Distillation Pipeline
A framework for distilling knowledge from large teacher models into smaller student models.
"""

__version__ = "1.0.0"
__author__ = "Lorenzo Mascia"
